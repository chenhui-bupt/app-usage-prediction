{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 222\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_data1=pd.read_csv('./output/node/nodesim1.csv',encoding='gbk')\n",
    "nb_data2=pd.read_csv('./output/node/nodesim2.csv',encoding='gbk')\n",
    "lp_data1=pd.read_csv('./output/path/lp1.csv',encoding='gbk')\n",
    "lp_data2=pd.read_csv('./output/path/lp2.csv',encoding='gbk')\n",
    "lsp_data1=pd.read_csv('./output/path/lsp1.csv',encoding='gbk')\n",
    "lsp_data2=pd.read_csv('./output/path/lsp2.csv',encoding='gbk')\n",
    "rwr_data1=pd.read_csv('./output/randomwalk/rwr1.csv',encoding='gbk')\n",
    "rwr_data2=pd.read_csv('./output/randomwalk/rwr.csv',encoding='gbk')\n",
    "rwrr_data1=pd.read_csv('./output/randomwalk/rwrr1.csv',encoding='gbk')\n",
    "rwrr_data2=pd.read_csv('./output/randomwalk/rwrr.csv',encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380480"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nb_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "    nb = GaussianNB()\n",
    "    knn = KNeighborsClassifier()\n",
    "    lr = LogisticRegression(penalty='l1')\n",
    "    rf = RandomForestClassifier(n_estimators=10, random_state=SEED)\n",
    "    xgb = XGBClassifier()\n",
    "    models = {\n",
    "              'knn': knn,\n",
    "              'naive bayes': nb,\n",
    "              'logistic': lr,\n",
    "              'random forest': rf,\n",
    "              'xgb': xgb,\n",
    "              }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Pred == Prob.apply(lambda p: 1*(p > 0.5))).sum() # 所以阈值为大于0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(models):\n",
    "    \"\"\"Fit models in list on training set and return preds\"\"\"\n",
    "    P = np.zeros((ytest.shape[0], len(models)))\n",
    "    P = pd.DataFrame(P)  # probability dataframe\n",
    "    print(\"Fitting models.\")\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(xtrain, ytrain)\n",
    "        P.iloc[:, i] = m.predict_proba(xtest)[:, 1]\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "    P.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P\n",
    "def score_models(P, y):\n",
    "    \"\"\"Score model in prediction DF\"\"\"\n",
    "    print(\"Scoring models.\")\n",
    "    eval_df = pd.DataFrame(np.zeros((len(P.columns), 6)), columns = ['model', 'accuracy', 'precision', 'recall', 'f1', 'auc'])\n",
    "    for i, m in enumerate(P.columns):\n",
    "        auc = roc_auc_score(y, P.loc[:, m])\n",
    "        pred = 1*(P.loc[:, m] > 0.5) # predict class\n",
    "        accuracy = accuracy_score(y, pred)\n",
    "        precision = precision_score(y, pred)\n",
    "        recall = recall_score(y, pred)\n",
    "        f1 = f1_score(y, pred)\n",
    "        print(\"%-26s: %f, %f, %f, %f, %f\" % (m, accuracy, precision, recall, f1, auc))\n",
    "        eval_df.iloc[i, :] = [m, accuracy, precision, recall, f1, auc]\n",
    "    return eval_df\n",
    "    print(\"Done.\\n\")\n",
    "def train_eval():\n",
    "    models = get_models()\n",
    "    P = train_predict(models)\n",
    "    eval_df = score_models(P, ytest)\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1=['CN','JC','AA','RA','PA','CS','LHN','HP','HD','SI']\n",
    "col2=['CN_2','JC_2','AA_2','RA_2','PA_2','CS_2','LHN_2','HP_2','HD_2','SI_2']\n",
    "nb11=np.mat(nb_data1.loc[:,col1])  \n",
    "nb12=np.mat(nb_data1.loc[:,col2])\n",
    "nb21=np.mat(nb_data2.loc[:,col1])\n",
    "nb22=np.mat(nb_data2.loc[:,col2])\n",
    "nb1= (nb11+nb12)/2.0    \n",
    "nb2= (nb21+nb22)/2.0\n",
    "cp1= (np.mat(nb_data1['CP'])+np.mat(nb_data1['CP_2']))/2.0    \n",
    "cp2= (np.mat(nb_data2['CP'])+np.mat(nb_data2['CP_2']))/2.0\n",
    "cp1=cp1.reshape(-1,1)    \n",
    "cp2=cp2.reshape(-1,1)\n",
    "lp1=np.mat(lp_data1['lp']+nb_data1['CN_2']).reshape(-1,1) \n",
    "lp2=np.mat(lp_data2['lp']+nb_data2['CN_2']).reshape(-1,1)\n",
    "lsp1=np.mat(lsp_data1['LSP']).reshape(-1,1)\n",
    "lsp2=np.mat(lsp_data2['LSP']).reshape(-1,1)\n",
    "rwr1=np.mat(rwr_data1['RWR']).reshape(-1,1)  \n",
    "rwr2=np.mat(rwr_data2['rwr']).reshape(-1,1)\n",
    "rwrr1=np.mat(rwrr_data1['RWRR']).reshape(-1,1)    \n",
    "rwrr2=np.mat(rwrr_data2['rwrr']).reshape(-1,1)\n",
    "NLR1=np.column_stack((nb1,lp1,rwr1))\n",
    "NLR2=np.column_stack((nb2,lp2,rwr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = nb1\n",
    "xtest = nb2\n",
    "\n",
    "ytrain=nb_data1['link'].values\n",
    "ytest=nb_data2['link'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.628124, 0.698651, 0.450611, 0.547864, 0.663138\n",
      "xgb                       : 0.901374, 0.919547, 0.879715, 0.899190, 0.953005\n",
      "logistic                  : 0.886252, 0.895609, 0.874425, 0.884890, 0.928593\n",
      "random forest             : 0.891552, 0.897304, 0.884314, 0.890762, 0.939377\n",
      "naive bayes               : 0.558723, 0.811743, 0.152908, 0.257341, 0.721241\n"
     ]
    }
   ],
   "source": [
    "eval_df = train_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Similarity is model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.040943794351595016, 0.042118092230221227)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytrain, lsp1), roc_auc_score(ytest, lsp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN 0.698396529539\n",
      "JC 0.691076123215\n",
      "AA 0.784942740163\n",
      "RA 0.792729689435\n",
      "PA 0.462915156947\n",
      "CS 0.770658462391\n",
      "LHN 0.798340390788\n",
      "HP 0.848538070877\n",
      "HD 0.669949069606\n",
      "SI 0.691076123215\n",
      "CP 0.852059033174\n",
      "CN_2 0.724988275221\n",
      "JC_2 0.615119263927\n",
      "AA_2 0.723936476968\n",
      "RA_2 0.720570155912\n",
      "PA_2 0.71658903797\n",
      "CS_2 0.728639444751\n",
      "LHN_2 0.513886708996\n",
      "HP_2 0.935801396012\n",
      "HD_2 0.600493820599\n",
      "SI_2 0.615119263927\n",
      "CP_2 0.954314130134\n"
     ]
    }
   ],
   "source": [
    "col1=['CN','JC','AA','RA','PA','CS','LHN','HP','HD','SI', 'CP']\n",
    "col2=['CN_2','JC_2','AA_2','RA_2','PA_2','CS_2','LHN_2','HP_2','HD_2','SI_2', 'CP_2']\n",
    "cols = col1 + col2\n",
    "for col in cols:\n",
    "    print(col, roc_auc_score(ytrain, nb_data1[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_edges = edges2 - edges1\n",
    "def unknown_unexist_data(data):\n",
    "    unknown_data = list(filter(lambda x: (x[0], x[1]) in unknown_edges, np.array(data)))\n",
    "    unknown_data = pd.DataFrame(unknown_data, columns=data.columns)\n",
    "    unexist_data = data.loc[data['link'] == 0].iloc[:len(unknown_data), :]\n",
    "    data = pd.concat([unknown_data, unexist_data], axis=0, ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_data = unknown_unexist_data(nb_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN 0.742974302293\n",
      "JC 0.512453009032\n",
      "AA 0.744044947481\n",
      "RA 0.741758212158\n",
      "PA 0.75331373231\n",
      "CS 0.549390919881\n",
      "LHN 0.274693620936\n",
      "HP 0.6537393029\n",
      "HD 0.505198838225\n",
      "SI 0.511504978509\n",
      "CP 0.72327184472\n"
     ]
    }
   ],
   "source": [
    "col1=['CN','JC','AA','RA','PA','CS','LHN','HP','HD','SI', 'CP']\n",
    "col2=['CN_2','JC_2','AA_2','RA_2','PA_2','CS_2','LHN_2','HP_2','HD_2','SI_2', 'CP_2']\n",
    "cols = col1 + col2\n",
    "for col in col1:\n",
    "    print(col, roc_auc_score(NB_data['link'], NB_data[col]+NB_data[col+'_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81842225910933797,\n",
       " 0.040943794351595016,\n",
       " 0.95987511278138071,\n",
       " 0.96274882510576265)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(ytrain, lp1), roc_auc_score(ytrain, lsp1), roc_auc_score(ytrain, rwr1), roc_auc_score(ytrain, rwrr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.870597501395\n",
      "0.13580601576\n",
      "0.876580409541\n",
      "0.866812570686\n"
     ]
    }
   ],
   "source": [
    "LP = unknown_unexist_data(lp_data1)\n",
    "print(roc_auc_score(LP['link'], LP['lp']))\n",
    "LSP = unknown_unexist_data(lsp_data1)\n",
    "print(roc_auc_score(LSP['link'], LSP['LSP']))\n",
    "RWR = unknown_unexist_data(rwr_data1)\n",
    "print(roc_auc_score(RWR['link'], RWR['RWR']))\n",
    "RWRR = unknown_unexist_data(rwrr_data1)\n",
    "print(roc_auc_score(RWRR['link'], RWRR['RWRR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Neighbor based similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.552205, 0.547048, 0.607003, 0.575468, 0.557549\n",
      "xgb                       : 0.662874, 0.687756, 0.596613, 0.638951, 0.732001\n",
      "logistic                  : 0.621621, 0.784347, 0.335482, 0.469955, 0.723205\n",
      "random forest             : 0.620788, 0.670481, 0.475043, 0.556091, 0.678736\n",
      "naive bayes               : 0.572470, 0.813377, 0.188096, 0.305536, 0.620423\n",
      "JC\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.687552, 0.681289, 0.704826, 0.692858, 0.717988\n",
      "xgb                       : 0.764416, 0.731868, 0.834602, 0.779867, 0.814720\n",
      "logistic                  : 0.610922, 0.657668, 0.462683, 0.543208, 0.724466\n",
      "random forest             : 0.689960, 0.714497, 0.632762, 0.671150, 0.731043\n",
      "naive bayes               : 0.564682, 0.674803, 0.249694, 0.364510, 0.620812\n",
      "AA\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.576877, 0.568400, 0.638841, 0.601566, 0.595021\n",
      "xgb                       : 0.671276, 0.675154, 0.660208, 0.667597, 0.745990\n",
      "logistic                  : 0.617294, 0.784947, 0.323111, 0.457783, 0.723776\n",
      "random forest             : 0.596195, 0.592545, 0.615916, 0.604004, 0.614917\n",
      "naive bayes               : 0.564555, 0.810634, 0.168464, 0.278955, 0.602002\n",
      "RA\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.578219, 0.583739, 0.545260, 0.563844, 0.599354\n",
      "xgb                       : 0.669960, 0.683927, 0.631993, 0.656935, 0.742956\n",
      "logistic                  : 0.611294, 0.787520, 0.304835, 0.439535, 0.722110\n",
      "random forest             : 0.612540, 0.637852, 0.520735, 0.573374, 0.628134\n",
      "naive bayes               : 0.558532, 0.812166, 0.152284, 0.256477, 0.573509\n",
      "PA\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.620414, 0.675324, 0.463818, 0.549936, 0.650740\n",
      "xgb                       : 0.654283, 0.674676, 0.595911, 0.632852, 0.714989\n",
      "logistic                  : 0.608422, 0.779962, 0.302059, 0.435471, 0.716864\n",
      "random forest             : 0.609599, 0.675151, 0.422467, 0.519724, 0.635759\n",
      "naive bayes               : 0.560437, 0.811006, 0.157599, 0.263914, 0.591307\n",
      "CS\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.691054, 0.685296, 0.706591, 0.695781, 0.709012\n",
      "xgb                       : 0.783342, 0.755910, 0.836940, 0.794364, 0.821670\n",
      "logistic                  : 0.758556, 0.766519, 0.743617, 0.754894, 0.815795\n",
      "random forest             : 0.685655, 0.705067, 0.638325, 0.670038, 0.718635\n",
      "naive bayes               : 0.699784, 0.783132, 0.552594, 0.647968, 0.815564\n",
      "LHN\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.616878, 0.681936, 0.438085, 0.533465, 0.590081\n",
      "xgb                       : 0.810812, 0.866158, 0.735235, 0.795345, 0.876443\n",
      "logistic                  : 0.787966, 0.791624, 0.781696, 0.786628, 0.793397\n",
      "random forest             : 0.672030, 0.893456, 0.390644, 0.543607, 0.602992\n",
      "naive bayes               : 0.760806, 0.860337, 0.622698, 0.722478, 0.793397\n",
      "HP\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.819937, 0.785858, 0.879545, 0.830066, 0.860649\n",
      "xgb                       : 0.873772, 0.893862, 0.848269, 0.870469, 0.920201\n",
      "logistic                  : 0.856454, 0.911857, 0.789195, 0.846103, 0.905420\n",
      "random forest             : 0.845825, 0.829271, 0.870962, 0.849605, 0.879685\n",
      "naive bayes               : 0.857249, 0.913564, 0.789164, 0.846820, 0.905420\n",
      "HD\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.668487, 0.656328, 0.707376, 0.680896, 0.697570\n",
      "xgb                       : 0.755983, 0.717611, 0.844150, 0.775754, 0.807054\n",
      "logistic                  : 0.582062, 0.623302, 0.414829, 0.498133, 0.697365\n",
      "random forest             : 0.684742, 0.699863, 0.646913, 0.672347, 0.722239\n",
      "naive bayes               : 0.549152, 0.638550, 0.226531, 0.334423, 0.565248\n",
      "SI\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.687433, 0.680597, 0.706359, 0.693239, 0.716581\n",
      "xgb                       : 0.764310, 0.727864, 0.844284, 0.781764, 0.817130\n",
      "logistic                  : 0.622994, 0.657840, 0.512611, 0.576216, 0.729126\n",
      "random forest             : 0.685887, 0.710046, 0.628380, 0.666721, 0.726853\n",
      "naive bayes               : 0.581607, 0.675572, 0.314012, 0.428741, 0.719561\n"
     ]
    }
   ],
   "source": [
    "# nb每一对特征\n",
    "cols=['CN','JC','AA','RA','PA','CS','LHN','HP','HD','SI'] + ['CP']\n",
    "ytrain = nb_data1['link'].values\n",
    "ytest = nb_data2['link'].values\n",
    "Eval = pd.DataFrame()\n",
    "for col in cols:\n",
    "    print(col)\n",
    "    xtrain = (nb_data1[col] + nb_data1[col+'_2']).reshape(-1,1)\n",
    "    xtest = (nb_data2[col] + nb_data2[col+'_2']).reshape(-1,1)\n",
    "    eval_df = train_eval()\n",
    "    Eval = Eval.append(pd.concat([pd.Series([col]*5, name='similarity'), eval_df], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.552205</td>\n",
       "      <td>0.547048</td>\n",
       "      <td>0.607003</td>\n",
       "      <td>0.575468</td>\n",
       "      <td>0.557549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.662874</td>\n",
       "      <td>0.687756</td>\n",
       "      <td>0.596613</td>\n",
       "      <td>0.638951</td>\n",
       "      <td>0.732001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.621621</td>\n",
       "      <td>0.784347</td>\n",
       "      <td>0.335482</td>\n",
       "      <td>0.469955</td>\n",
       "      <td>0.723205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.620788</td>\n",
       "      <td>0.670481</td>\n",
       "      <td>0.475043</td>\n",
       "      <td>0.556091</td>\n",
       "      <td>0.678736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.572470</td>\n",
       "      <td>0.813377</td>\n",
       "      <td>0.188096</td>\n",
       "      <td>0.305536</td>\n",
       "      <td>0.620423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JC</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.687552</td>\n",
       "      <td>0.681289</td>\n",
       "      <td>0.704826</td>\n",
       "      <td>0.692858</td>\n",
       "      <td>0.717988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JC</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.764416</td>\n",
       "      <td>0.731868</td>\n",
       "      <td>0.834602</td>\n",
       "      <td>0.779867</td>\n",
       "      <td>0.814720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JC</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.610922</td>\n",
       "      <td>0.657668</td>\n",
       "      <td>0.462683</td>\n",
       "      <td>0.543208</td>\n",
       "      <td>0.724466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JC</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.689960</td>\n",
       "      <td>0.714497</td>\n",
       "      <td>0.632762</td>\n",
       "      <td>0.671150</td>\n",
       "      <td>0.731043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JC</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.564682</td>\n",
       "      <td>0.674803</td>\n",
       "      <td>0.249694</td>\n",
       "      <td>0.364510</td>\n",
       "      <td>0.620812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.576877</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.638841</td>\n",
       "      <td>0.601566</td>\n",
       "      <td>0.595021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.671276</td>\n",
       "      <td>0.675154</td>\n",
       "      <td>0.660208</td>\n",
       "      <td>0.667597</td>\n",
       "      <td>0.745990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.617294</td>\n",
       "      <td>0.784947</td>\n",
       "      <td>0.323111</td>\n",
       "      <td>0.457783</td>\n",
       "      <td>0.723776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.596195</td>\n",
       "      <td>0.592545</td>\n",
       "      <td>0.615916</td>\n",
       "      <td>0.604004</td>\n",
       "      <td>0.614917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.564555</td>\n",
       "      <td>0.810634</td>\n",
       "      <td>0.168464</td>\n",
       "      <td>0.278955</td>\n",
       "      <td>0.602002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RA</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.578219</td>\n",
       "      <td>0.583739</td>\n",
       "      <td>0.545260</td>\n",
       "      <td>0.563844</td>\n",
       "      <td>0.599354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RA</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.669960</td>\n",
       "      <td>0.683927</td>\n",
       "      <td>0.631993</td>\n",
       "      <td>0.656935</td>\n",
       "      <td>0.742956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RA</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.611294</td>\n",
       "      <td>0.787520</td>\n",
       "      <td>0.304835</td>\n",
       "      <td>0.439535</td>\n",
       "      <td>0.722110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RA</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.612540</td>\n",
       "      <td>0.637852</td>\n",
       "      <td>0.520735</td>\n",
       "      <td>0.573374</td>\n",
       "      <td>0.628134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RA</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.558532</td>\n",
       "      <td>0.812166</td>\n",
       "      <td>0.152284</td>\n",
       "      <td>0.256477</td>\n",
       "      <td>0.573509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.620414</td>\n",
       "      <td>0.675324</td>\n",
       "      <td>0.463818</td>\n",
       "      <td>0.549936</td>\n",
       "      <td>0.650740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PA</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.654283</td>\n",
       "      <td>0.674676</td>\n",
       "      <td>0.595911</td>\n",
       "      <td>0.632852</td>\n",
       "      <td>0.714989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PA</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.608422</td>\n",
       "      <td>0.779962</td>\n",
       "      <td>0.302059</td>\n",
       "      <td>0.435471</td>\n",
       "      <td>0.716864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PA</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.609599</td>\n",
       "      <td>0.675151</td>\n",
       "      <td>0.422467</td>\n",
       "      <td>0.519724</td>\n",
       "      <td>0.635759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PA</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.560437</td>\n",
       "      <td>0.811006</td>\n",
       "      <td>0.157599</td>\n",
       "      <td>0.263914</td>\n",
       "      <td>0.591307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.691054</td>\n",
       "      <td>0.685296</td>\n",
       "      <td>0.706591</td>\n",
       "      <td>0.695781</td>\n",
       "      <td>0.709012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.783342</td>\n",
       "      <td>0.755910</td>\n",
       "      <td>0.836940</td>\n",
       "      <td>0.794364</td>\n",
       "      <td>0.821670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.758556</td>\n",
       "      <td>0.766519</td>\n",
       "      <td>0.743617</td>\n",
       "      <td>0.754894</td>\n",
       "      <td>0.815795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.685655</td>\n",
       "      <td>0.705067</td>\n",
       "      <td>0.638325</td>\n",
       "      <td>0.670038</td>\n",
       "      <td>0.718635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.699784</td>\n",
       "      <td>0.783132</td>\n",
       "      <td>0.552594</td>\n",
       "      <td>0.647968</td>\n",
       "      <td>0.815564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LHN</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.616878</td>\n",
       "      <td>0.681936</td>\n",
       "      <td>0.438085</td>\n",
       "      <td>0.533465</td>\n",
       "      <td>0.590081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LHN</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.810812</td>\n",
       "      <td>0.866158</td>\n",
       "      <td>0.735235</td>\n",
       "      <td>0.795345</td>\n",
       "      <td>0.876443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LHN</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.787966</td>\n",
       "      <td>0.791624</td>\n",
       "      <td>0.781696</td>\n",
       "      <td>0.786628</td>\n",
       "      <td>0.793397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LHN</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.672030</td>\n",
       "      <td>0.893456</td>\n",
       "      <td>0.390644</td>\n",
       "      <td>0.543607</td>\n",
       "      <td>0.602992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LHN</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.760806</td>\n",
       "      <td>0.860337</td>\n",
       "      <td>0.622698</td>\n",
       "      <td>0.722478</td>\n",
       "      <td>0.793397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.819937</td>\n",
       "      <td>0.785858</td>\n",
       "      <td>0.879545</td>\n",
       "      <td>0.830066</td>\n",
       "      <td>0.860649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.873772</td>\n",
       "      <td>0.893862</td>\n",
       "      <td>0.848269</td>\n",
       "      <td>0.870469</td>\n",
       "      <td>0.920201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.856454</td>\n",
       "      <td>0.911857</td>\n",
       "      <td>0.789195</td>\n",
       "      <td>0.846103</td>\n",
       "      <td>0.905420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.845825</td>\n",
       "      <td>0.829271</td>\n",
       "      <td>0.870962</td>\n",
       "      <td>0.849605</td>\n",
       "      <td>0.879685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.857249</td>\n",
       "      <td>0.913564</td>\n",
       "      <td>0.789164</td>\n",
       "      <td>0.846820</td>\n",
       "      <td>0.905420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HD</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.668487</td>\n",
       "      <td>0.656328</td>\n",
       "      <td>0.707376</td>\n",
       "      <td>0.680896</td>\n",
       "      <td>0.697570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HD</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.755983</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>0.844150</td>\n",
       "      <td>0.775754</td>\n",
       "      <td>0.807054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HD</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.582062</td>\n",
       "      <td>0.623302</td>\n",
       "      <td>0.414829</td>\n",
       "      <td>0.498133</td>\n",
       "      <td>0.697365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.684742</td>\n",
       "      <td>0.699863</td>\n",
       "      <td>0.646913</td>\n",
       "      <td>0.672347</td>\n",
       "      <td>0.722239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.549152</td>\n",
       "      <td>0.638550</td>\n",
       "      <td>0.226531</td>\n",
       "      <td>0.334423</td>\n",
       "      <td>0.565248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.687433</td>\n",
       "      <td>0.680597</td>\n",
       "      <td>0.706359</td>\n",
       "      <td>0.693239</td>\n",
       "      <td>0.716581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.764310</td>\n",
       "      <td>0.727864</td>\n",
       "      <td>0.844284</td>\n",
       "      <td>0.781764</td>\n",
       "      <td>0.817130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SI</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.622994</td>\n",
       "      <td>0.657840</td>\n",
       "      <td>0.512611</td>\n",
       "      <td>0.576216</td>\n",
       "      <td>0.729126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SI</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.685887</td>\n",
       "      <td>0.710046</td>\n",
       "      <td>0.628380</td>\n",
       "      <td>0.666721</td>\n",
       "      <td>0.726853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SI</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.581607</td>\n",
       "      <td>0.675572</td>\n",
       "      <td>0.314012</td>\n",
       "      <td>0.428741</td>\n",
       "      <td>0.719561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.861920</td>\n",
       "      <td>0.840753</td>\n",
       "      <td>0.892979</td>\n",
       "      <td>0.866079</td>\n",
       "      <td>0.894526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.903658</td>\n",
       "      <td>0.918958</td>\n",
       "      <td>0.885398</td>\n",
       "      <td>0.901866</td>\n",
       "      <td>0.947947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.887498</td>\n",
       "      <td>0.957950</td>\n",
       "      <td>0.810577</td>\n",
       "      <td>0.878123</td>\n",
       "      <td>0.930970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.886796</td>\n",
       "      <td>0.891529</td>\n",
       "      <td>0.880753</td>\n",
       "      <td>0.886108</td>\n",
       "      <td>0.925217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.882915</td>\n",
       "      <td>0.960180</td>\n",
       "      <td>0.798965</td>\n",
       "      <td>0.872185</td>\n",
       "      <td>0.930970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  similarity          model  accuracy  precision    recall        f1       auc\n",
       "0         CN            knn  0.552205   0.547048  0.607003  0.575468  0.557549\n",
       "1         CN            xgb  0.662874   0.687756  0.596613  0.638951  0.732001\n",
       "2         CN       logistic  0.621621   0.784347  0.335482  0.469955  0.723205\n",
       "3         CN  random forest  0.620788   0.670481  0.475043  0.556091  0.678736\n",
       "4         CN    naive bayes  0.572470   0.813377  0.188096  0.305536  0.620423\n",
       "0         JC            knn  0.687552   0.681289  0.704826  0.692858  0.717988\n",
       "1         JC            xgb  0.764416   0.731868  0.834602  0.779867  0.814720\n",
       "2         JC       logistic  0.610922   0.657668  0.462683  0.543208  0.724466\n",
       "3         JC  random forest  0.689960   0.714497  0.632762  0.671150  0.731043\n",
       "4         JC    naive bayes  0.564682   0.674803  0.249694  0.364510  0.620812\n",
       "0         AA            knn  0.576877   0.568400  0.638841  0.601566  0.595021\n",
       "1         AA            xgb  0.671276   0.675154  0.660208  0.667597  0.745990\n",
       "2         AA       logistic  0.617294   0.784947  0.323111  0.457783  0.723776\n",
       "3         AA  random forest  0.596195   0.592545  0.615916  0.604004  0.614917\n",
       "4         AA    naive bayes  0.564555   0.810634  0.168464  0.278955  0.602002\n",
       "0         RA            knn  0.578219   0.583739  0.545260  0.563844  0.599354\n",
       "1         RA            xgb  0.669960   0.683927  0.631993  0.656935  0.742956\n",
       "2         RA       logistic  0.611294   0.787520  0.304835  0.439535  0.722110\n",
       "3         RA  random forest  0.612540   0.637852  0.520735  0.573374  0.628134\n",
       "4         RA    naive bayes  0.558532   0.812166  0.152284  0.256477  0.573509\n",
       "0         PA            knn  0.620414   0.675324  0.463818  0.549936  0.650740\n",
       "1         PA            xgb  0.654283   0.674676  0.595911  0.632852  0.714989\n",
       "2         PA       logistic  0.608422   0.779962  0.302059  0.435471  0.716864\n",
       "3         PA  random forest  0.609599   0.675151  0.422467  0.519724  0.635759\n",
       "4         PA    naive bayes  0.560437   0.811006  0.157599  0.263914  0.591307\n",
       "0         CS            knn  0.691054   0.685296  0.706591  0.695781  0.709012\n",
       "1         CS            xgb  0.783342   0.755910  0.836940  0.794364  0.821670\n",
       "2         CS       logistic  0.758556   0.766519  0.743617  0.754894  0.815795\n",
       "3         CS  random forest  0.685655   0.705067  0.638325  0.670038  0.718635\n",
       "4         CS    naive bayes  0.699784   0.783132  0.552594  0.647968  0.815564\n",
       "0        LHN            knn  0.616878   0.681936  0.438085  0.533465  0.590081\n",
       "1        LHN            xgb  0.810812   0.866158  0.735235  0.795345  0.876443\n",
       "2        LHN       logistic  0.787966   0.791624  0.781696  0.786628  0.793397\n",
       "3        LHN  random forest  0.672030   0.893456  0.390644  0.543607  0.602992\n",
       "4        LHN    naive bayes  0.760806   0.860337  0.622698  0.722478  0.793397\n",
       "0         HP            knn  0.819937   0.785858  0.879545  0.830066  0.860649\n",
       "1         HP            xgb  0.873772   0.893862  0.848269  0.870469  0.920201\n",
       "2         HP       logistic  0.856454   0.911857  0.789195  0.846103  0.905420\n",
       "3         HP  random forest  0.845825   0.829271  0.870962  0.849605  0.879685\n",
       "4         HP    naive bayes  0.857249   0.913564  0.789164  0.846820  0.905420\n",
       "0         HD            knn  0.668487   0.656328  0.707376  0.680896  0.697570\n",
       "1         HD            xgb  0.755983   0.717611  0.844150  0.775754  0.807054\n",
       "2         HD       logistic  0.582062   0.623302  0.414829  0.498133  0.697365\n",
       "3         HD  random forest  0.684742   0.699863  0.646913  0.672347  0.722239\n",
       "4         HD    naive bayes  0.549152   0.638550  0.226531  0.334423  0.565248\n",
       "0         SI            knn  0.687433   0.680597  0.706359  0.693239  0.716581\n",
       "1         SI            xgb  0.764310   0.727864  0.844284  0.781764  0.817130\n",
       "2         SI       logistic  0.622994   0.657840  0.512611  0.576216  0.729126\n",
       "3         SI  random forest  0.685887   0.710046  0.628380  0.666721  0.726853\n",
       "4         SI    naive bayes  0.581607   0.675572  0.314012  0.428741  0.719561\n",
       "0         CP            knn  0.861920   0.840753  0.892979  0.866079  0.894526\n",
       "1         CP            xgb  0.903658   0.918958  0.885398  0.901866  0.947947\n",
       "2         CP       logistic  0.887498   0.957950  0.810577  0.878123  0.930970\n",
       "3         CP  random forest  0.886796   0.891529  0.880753  0.886108  0.925217\n",
       "4         CP    naive bayes  0.882915   0.960180  0.798965  0.872185  0.930970"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval.to_csv('./output/modelresult2/eval_nb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.552205</td>\n",
       "      <td>0.547048</td>\n",
       "      <td>0.607003</td>\n",
       "      <td>0.575468</td>\n",
       "      <td>0.557549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.662874</td>\n",
       "      <td>0.687756</td>\n",
       "      <td>0.596613</td>\n",
       "      <td>0.638951</td>\n",
       "      <td>0.732001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.621621</td>\n",
       "      <td>0.784347</td>\n",
       "      <td>0.335482</td>\n",
       "      <td>0.469955</td>\n",
       "      <td>0.723205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.620788</td>\n",
       "      <td>0.670481</td>\n",
       "      <td>0.475043</td>\n",
       "      <td>0.556091</td>\n",
       "      <td>0.678736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.572470</td>\n",
       "      <td>0.813377</td>\n",
       "      <td>0.188096</td>\n",
       "      <td>0.305536</td>\n",
       "      <td>0.620423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  similarity          model  accuracy  precision    recall        f1       auc\n",
       "0         CN            knn  0.552205   0.547048  0.607003  0.575468  0.557549\n",
       "1         CN            xgb  0.662874   0.687756  0.596613  0.638951  0.732001\n",
       "2         CN       logistic  0.621621   0.784347  0.335482  0.469955  0.723205\n",
       "3         CN  random forest  0.620788   0.670481  0.475043  0.556091  0.678736\n",
       "4         CN    naive bayes  0.572470   0.813377  0.188096  0.305536  0.620423"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval = pd.read_csv('./output/modelresult2/eval_nb.csv')\n",
    "Eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_name = {\n",
    "    'PA': 'Preferential Attachment','CN': 'Common Neighbors', 'CS': 'Salton', 'JC': 'Jaccard',\n",
    "    'AA': 'Adamic-Adar', 'RA': 'Resource Allocation', 'SI': 'Sorence', 'LHN': 'Leicht-Holme-Newman',\n",
    "    'HD': 'Hub Depressed Index', 'HP':'Hub Promoted Index', 'CP': 'Bidirectional Conditional Probability',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcy/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i in range(len(Eval)):\n",
    "    e = Eval.iloc[i, :]\n",
    "    data.setdefault(e[1], dict())\n",
    "#     if e[0]=='SI':\n",
    "#         e[0] = 'Sorence'\n",
    "    e[0] = full_name[e[0]]\n",
    "    data[e[1]][e[0]] = e[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>logistic</th>\n",
       "      <th>naive bayes</th>\n",
       "      <th>random forest</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Preferential Attachment</th>\n",
       "      <td>0.650740</td>\n",
       "      <td>0.716864</td>\n",
       "      <td>0.591307</td>\n",
       "      <td>0.635759</td>\n",
       "      <td>0.714989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Common Neighbors</th>\n",
       "      <td>0.557549</td>\n",
       "      <td>0.723205</td>\n",
       "      <td>0.620423</td>\n",
       "      <td>0.678736</td>\n",
       "      <td>0.732001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salton</th>\n",
       "      <td>0.709012</td>\n",
       "      <td>0.815795</td>\n",
       "      <td>0.815564</td>\n",
       "      <td>0.718635</td>\n",
       "      <td>0.821670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.717988</td>\n",
       "      <td>0.724466</td>\n",
       "      <td>0.620812</td>\n",
       "      <td>0.731043</td>\n",
       "      <td>0.814720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adamic-Adar</th>\n",
       "      <td>0.595021</td>\n",
       "      <td>0.723776</td>\n",
       "      <td>0.602002</td>\n",
       "      <td>0.614917</td>\n",
       "      <td>0.745990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Allocation</th>\n",
       "      <td>0.599354</td>\n",
       "      <td>0.722110</td>\n",
       "      <td>0.573509</td>\n",
       "      <td>0.628134</td>\n",
       "      <td>0.742956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sorence</th>\n",
       "      <td>0.716581</td>\n",
       "      <td>0.729126</td>\n",
       "      <td>0.719561</td>\n",
       "      <td>0.726853</td>\n",
       "      <td>0.817130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leicht-Holme-Newman</th>\n",
       "      <td>0.590081</td>\n",
       "      <td>0.793397</td>\n",
       "      <td>0.793397</td>\n",
       "      <td>0.602992</td>\n",
       "      <td>0.876443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hub Depressed Index</th>\n",
       "      <td>0.697570</td>\n",
       "      <td>0.697365</td>\n",
       "      <td>0.565248</td>\n",
       "      <td>0.722239</td>\n",
       "      <td>0.807054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hub Promoted Index</th>\n",
       "      <td>0.860649</td>\n",
       "      <td>0.905420</td>\n",
       "      <td>0.905420</td>\n",
       "      <td>0.879685</td>\n",
       "      <td>0.920201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bidirectional Conditional Probability</th>\n",
       "      <td>0.894526</td>\n",
       "      <td>0.930970</td>\n",
       "      <td>0.930970</td>\n",
       "      <td>0.925217</td>\n",
       "      <td>0.947947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            knn  logistic  naive bayes  \\\n",
       "Preferential Attachment                0.650740  0.716864     0.591307   \n",
       "Common Neighbors                       0.557549  0.723205     0.620423   \n",
       "Salton                                 0.709012  0.815795     0.815564   \n",
       "Jaccard                                0.717988  0.724466     0.620812   \n",
       "Adamic-Adar                            0.595021  0.723776     0.602002   \n",
       "Resource Allocation                    0.599354  0.722110     0.573509   \n",
       "Sorence                                0.716581  0.729126     0.719561   \n",
       "Leicht-Holme-Newman                    0.590081  0.793397     0.793397   \n",
       "Hub Depressed Index                    0.697570  0.697365     0.565248   \n",
       "Hub Promoted Index                     0.860649  0.905420     0.905420   \n",
       "Bidirectional Conditional Probability  0.894526  0.930970     0.930970   \n",
       "\n",
       "                                       random forest       xgb  \n",
       "Preferential Attachment                     0.635759  0.714989  \n",
       "Common Neighbors                            0.678736  0.732001  \n",
       "Salton                                      0.718635  0.821670  \n",
       "Jaccard                                     0.731043  0.814720  \n",
       "Adamic-Adar                                 0.614917  0.745990  \n",
       "Resource Allocation                         0.628134  0.742956  \n",
       "Sorence                                     0.726853  0.817130  \n",
       "Leicht-Holme-Newman                         0.602992  0.876443  \n",
       "Hub Depressed Index                         0.722239  0.807054  \n",
       "Hub Promoted Index                          0.879685  0.920201  \n",
       "Bidirectional Conditional Probability       0.925217  0.947947  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xticks = ['PA','CN','CS','JC','AA','RA','Sorence','LHN','HD','HP','CP']\n",
    "xticks = ['Preferential Attachment', 'Common Neighbors', 'Salton', 'Jaccard', 'Adamic-Adar', 'Resource Allocation',\n",
    "         'Sorence', 'Leicht-Holme-Newman', 'Hub Depressed Index', 'Hub Promoted Index', 'Bidirectional Conditional Probability']\n",
    "df = pd.DataFrame(data).loc[xticks]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAHkCAYAAAC9uxxDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe980d0860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.set_xlabel('Neighbor based similarity')\n",
    "ax.set_ylabel('AUC')\n",
    "df.plot(ax=ax, xticks = range(11), legend='reverse', ylim=[0.12, 1.0], rot = 90, fontsize=5)\n",
    "plt.savefig('./output/pics3/neighbors_based.jpg',dpi=600,bbox_inches='tight')\n",
    "plt.savefig('./output/pics3/neighbors_based.eps',dpi=600,bbox_inches='tight')\n",
    "plt.savefig('./output/pics3/neighbors_based.pdf',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Path based similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.901694, 0.905962, 0.896437, 0.901174, 0.936325\n",
      "xgb                       : 0.912904, 0.928676, 0.894507, 0.911271, 0.961632\n",
      "logistic                  : 0.837843, 0.968548, 0.698364, 0.811560, 0.961415\n",
      "random forest             : 0.878061, 0.962076, 0.787151, 0.865867, 0.879532\n",
      "naive bayes               : 0.802621, 0.971289, 0.623678, 0.759604, 0.961402\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.723352, 0.702599, 0.774568, 0.736830, 0.770193\n",
      "xgb                       : 0.771964, 0.735193, 0.850137, 0.788498, 0.826409\n",
      "logistic                  : 0.627709, 0.788683, 0.348901, 0.483784, 0.815863\n",
      "random forest             : 0.700751, 0.687115, 0.737191, 0.711273, 0.748715\n",
      "naive bayes               : 0.576033, 0.817664, 0.195709, 0.315825, 0.645890\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.899013, 0.899301, 0.898651, 0.898976, 0.933818\n",
      "xgb                       : 0.907694, 0.914140, 0.899911, 0.906970, 0.959260\n",
      "logistic                  : 0.900933, 0.928715, 0.868531, 0.897615, 0.958367\n",
      "random forest             : 0.880631, 0.894284, 0.863318, 0.878528, 0.921162\n",
      "naive bayes               : 0.893973, 0.928930, 0.853223, 0.889469, 0.958367\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.896174, 0.908456, 0.881140, 0.894589, 0.939857\n",
      "xgb                       : 0.904788, 0.933196, 0.871999, 0.901560, 0.957811\n",
      "logistic                  : 0.878825, 0.961908, 0.788890, 0.866850, 0.957882\n",
      "random forest             : 0.903632, 0.928451, 0.874668, 0.900757, 0.955815\n",
      "naive bayes               : 0.878799, 0.961848, 0.788890, 0.866826, 0.957871\n"
     ]
    }
   ],
   "source": [
    "Eval = pd.DataFrame()\n",
    "sim_data = {\n",
    "    'lp': [lp1, lp2],\n",
    "    'lsp': [lsp1, lsp2],\n",
    "    'rwr': [rwr1, rwr2],\n",
    "    'rwrr': [rwrr1, rwrr2]\n",
    "}\n",
    "for name, sim in sim_data.items():\n",
    "    xtrain, xtest = sim\n",
    "    eval_df = train_eval()\n",
    "    Eval = Eval.append(pd.concat([pd.Series([name.upper()]*5, name='similarity'), eval_df], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Eval.to_csv('./output/modelresult2/eval_path.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWRR</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.901694</td>\n",
       "      <td>0.905962</td>\n",
       "      <td>0.896437</td>\n",
       "      <td>0.901174</td>\n",
       "      <td>0.936325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RWRR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.912904</td>\n",
       "      <td>0.928676</td>\n",
       "      <td>0.894507</td>\n",
       "      <td>0.911271</td>\n",
       "      <td>0.961632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RWRR</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.837843</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.698364</td>\n",
       "      <td>0.811560</td>\n",
       "      <td>0.961415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RWRR</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.878061</td>\n",
       "      <td>0.962076</td>\n",
       "      <td>0.787151</td>\n",
       "      <td>0.865867</td>\n",
       "      <td>0.879532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RWRR</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.802621</td>\n",
       "      <td>0.971289</td>\n",
       "      <td>0.623678</td>\n",
       "      <td>0.759604</td>\n",
       "      <td>0.961402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.723352</td>\n",
       "      <td>0.702599</td>\n",
       "      <td>0.774568</td>\n",
       "      <td>0.736830</td>\n",
       "      <td>0.770193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.771964</td>\n",
       "      <td>0.735193</td>\n",
       "      <td>0.850137</td>\n",
       "      <td>0.788498</td>\n",
       "      <td>0.826409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.627709</td>\n",
       "      <td>0.788683</td>\n",
       "      <td>0.348901</td>\n",
       "      <td>0.483784</td>\n",
       "      <td>0.815863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.700751</td>\n",
       "      <td>0.687115</td>\n",
       "      <td>0.737191</td>\n",
       "      <td>0.711273</td>\n",
       "      <td>0.748715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.576033</td>\n",
       "      <td>0.817664</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.315825</td>\n",
       "      <td>0.645890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWR</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.899013</td>\n",
       "      <td>0.899301</td>\n",
       "      <td>0.898651</td>\n",
       "      <td>0.898976</td>\n",
       "      <td>0.933818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RWR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.907694</td>\n",
       "      <td>0.914140</td>\n",
       "      <td>0.899911</td>\n",
       "      <td>0.906970</td>\n",
       "      <td>0.959260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RWR</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.900933</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>0.868531</td>\n",
       "      <td>0.897615</td>\n",
       "      <td>0.958367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RWR</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.880631</td>\n",
       "      <td>0.894284</td>\n",
       "      <td>0.863318</td>\n",
       "      <td>0.878528</td>\n",
       "      <td>0.921162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RWR</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.893973</td>\n",
       "      <td>0.928930</td>\n",
       "      <td>0.853223</td>\n",
       "      <td>0.889469</td>\n",
       "      <td>0.958367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.896174</td>\n",
       "      <td>0.908456</td>\n",
       "      <td>0.881140</td>\n",
       "      <td>0.894589</td>\n",
       "      <td>0.939857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.933196</td>\n",
       "      <td>0.871999</td>\n",
       "      <td>0.901560</td>\n",
       "      <td>0.957811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.878825</td>\n",
       "      <td>0.961908</td>\n",
       "      <td>0.788890</td>\n",
       "      <td>0.866850</td>\n",
       "      <td>0.957882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.903632</td>\n",
       "      <td>0.928451</td>\n",
       "      <td>0.874668</td>\n",
       "      <td>0.900757</td>\n",
       "      <td>0.955815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.878799</td>\n",
       "      <td>0.961848</td>\n",
       "      <td>0.788890</td>\n",
       "      <td>0.866826</td>\n",
       "      <td>0.957871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  similarity          model  accuracy  precision    recall        f1       auc\n",
       "0       RWRR            knn  0.901694   0.905962  0.896437  0.901174  0.936325\n",
       "1       RWRR            xgb  0.912904   0.928676  0.894507  0.911271  0.961632\n",
       "2       RWRR       logistic  0.837843   0.968548  0.698364  0.811560  0.961415\n",
       "3       RWRR  random forest  0.878061   0.962076  0.787151  0.865867  0.879532\n",
       "4       RWRR    naive bayes  0.802621   0.971289  0.623678  0.759604  0.961402\n",
       "0         LP            knn  0.723352   0.702599  0.774568  0.736830  0.770193\n",
       "1         LP            xgb  0.771964   0.735193  0.850137  0.788498  0.826409\n",
       "2         LP       logistic  0.627709   0.788683  0.348901  0.483784  0.815863\n",
       "3         LP  random forest  0.700751   0.687115  0.737191  0.711273  0.748715\n",
       "4         LP    naive bayes  0.576033   0.817664  0.195709  0.315825  0.645890\n",
       "0        RWR            knn  0.899013   0.899301  0.898651  0.898976  0.933818\n",
       "1        RWR            xgb  0.907694   0.914140  0.899911  0.906970  0.959260\n",
       "2        RWR       logistic  0.900933   0.928715  0.868531  0.897615  0.958367\n",
       "3        RWR  random forest  0.880631   0.894284  0.863318  0.878528  0.921162\n",
       "4        RWR    naive bayes  0.893973   0.928930  0.853223  0.889469  0.958367\n",
       "0        LSP            knn  0.896174   0.908456  0.881140  0.894589  0.939857\n",
       "1        LSP            xgb  0.904788   0.933196  0.871999  0.901560  0.957811\n",
       "2        LSP       logistic  0.878825   0.961908  0.788890  0.866850  0.957882\n",
       "3        LSP  random forest  0.903632   0.928451  0.874668  0.900757  0.955815\n",
       "4        LSP    naive bayes  0.878799   0.961848  0.788890  0.866826  0.957871"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "figure-path-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Eval = pd.read_csv('./output/modelresult2/eval_path.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_name = {\n",
    "    'LP': 'Local Path', 'LSP': 'Local Shortest Path', \n",
    "    'RWR': 'Random Walk with Restart', 'RWRR': 'Random Walk with Resource Redistribution',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcy/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>logistic</th>\n",
       "      <th>naive bayes</th>\n",
       "      <th>random forest</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LP</th>\n",
       "      <td>0.770193</td>\n",
       "      <td>0.815863</td>\n",
       "      <td>0.645890</td>\n",
       "      <td>0.748715</td>\n",
       "      <td>0.826409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSP</th>\n",
       "      <td>0.939857</td>\n",
       "      <td>0.957882</td>\n",
       "      <td>0.957871</td>\n",
       "      <td>0.955815</td>\n",
       "      <td>0.957811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RWR</th>\n",
       "      <td>0.933818</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>0.921162</td>\n",
       "      <td>0.959260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RWRR</th>\n",
       "      <td>0.936325</td>\n",
       "      <td>0.961415</td>\n",
       "      <td>0.961402</td>\n",
       "      <td>0.879532</td>\n",
       "      <td>0.961632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           knn  logistic  naive bayes  random forest       xgb\n",
       "LP    0.770193  0.815863     0.645890       0.748715  0.826409\n",
       "LSP   0.939857  0.957882     0.957871       0.955815  0.957811\n",
       "RWR   0.933818  0.958367     0.958367       0.921162  0.959260\n",
       "RWRR  0.936325  0.961415     0.961402       0.879532  0.961632"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "for i in range(len(Eval)):\n",
    "    e = Eval.iloc[i, :]\n",
    "    data.setdefault(e[1], dict())\n",
    "#     e[0] = full_name[e[0]]\n",
    "    e[0] = e[0]\n",
    "    data[e[1]][e[0]] = e[6]\n",
    "\n",
    "# xticks = ['Local Path', 'Local Shortest Path', 'Random Walk with Restart', 'Random Walk with Resource Redistribution']\n",
    "xticks = ['LP', 'LSP', 'RWR', 'RWRR']\n",
    "df = pd.DataFrame(data).loc[xticks]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAF5CAYAAABqeatVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe98474f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.set_xlabel('Path based similarity')\n",
    "ax.set_ylabel('AUC')\n",
    "df.plot(ax=ax, xticks = range(4), legend='reverse')\n",
    "plt.savefig('./output/pics3/path_based2.jpg',dpi=600,bbox_inches='tight')\n",
    "plt.savefig('./output/pics3/path_based2.eps',dpi=600,bbox_inches='tight')\n",
    "plt.savefig('./output/pics3/path_based2.pdf',dpi=600,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. RWR vs. RWRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, os\n",
    "rw_list = list(filter(lambda x : re.search('rwr.*\\.csv', x) ,os.listdir('./output/randomwalk/')))\n",
    "len(rw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rwr+1000.csv',\n",
       " 'rwr+10000.csv',\n",
       " 'rwr+11000.csv',\n",
       " 'rwr+13000.csv',\n",
       " 'rwr+15000.csv',\n",
       " 'rwr+17000.csv',\n",
       " 'rwr+19000.csv',\n",
       " 'rwr+20000.csv',\n",
       " 'rwr+21000.csv',\n",
       " 'rwr+23000.csv',\n",
       " 'rwr+2500.csv',\n",
       " 'rwr+25000.csv',\n",
       " 'rwr+27000.csv',\n",
       " 'rwr+29000.csv',\n",
       " 'rwr+3000.csv',\n",
       " 'rwr+31000.csv',\n",
       " 'rwr+33000.csv',\n",
       " 'rwr+35000.csv',\n",
       " 'rwr+37000.csv',\n",
       " 'rwr+39000.csv',\n",
       " 'rwr+40000.csv',\n",
       " 'rwr+5000.csv',\n",
       " 'rwr+7000.csv',\n",
       " 'rwr+9000.csv',\n",
       " 'rwr-1000.csv',\n",
       " 'rwr-10000.csv',\n",
       " 'rwr-11000.csv',\n",
       " 'rwr-13000.csv',\n",
       " 'rwr-15000.csv',\n",
       " 'rwr-17000.csv',\n",
       " 'rwr-19000.csv',\n",
       " 'rwr-20000.csv',\n",
       " 'rwr-21000.csv',\n",
       " 'rwr-23000.csv',\n",
       " 'rwr-2500.csv',\n",
       " 'rwr-25000.csv',\n",
       " 'rwr-27000.csv',\n",
       " 'rwr-29000.csv',\n",
       " 'rwr-3000.csv',\n",
       " 'rwr-31000.csv',\n",
       " 'rwr-33000.csv',\n",
       " 'rwr-35000.csv',\n",
       " 'rwr-37000.csv',\n",
       " 'rwr-39000.csv',\n",
       " 'rwr-40000.csv',\n",
       " 'rwr-5000.csv',\n",
       " 'rwr-7000.csv',\n",
       " 'rwr-9000.csv',\n",
       " 'rwr.csv',\n",
       " 'rwr1.csv',\n",
       " 'rwrr+1000.csv',\n",
       " 'rwrr+10000.csv',\n",
       " 'rwrr+11000.csv',\n",
       " 'rwrr+13000.csv',\n",
       " 'rwrr+15000.csv',\n",
       " 'rwrr+17000.csv',\n",
       " 'rwrr+19000.csv',\n",
       " 'rwrr+20000.csv',\n",
       " 'rwrr+21000.csv',\n",
       " 'rwrr+23000.csv',\n",
       " 'rwrr+2500.csv',\n",
       " 'rwrr+25000.csv',\n",
       " 'rwrr+27000.csv',\n",
       " 'rwrr+29000.csv',\n",
       " 'rwrr+3000.csv',\n",
       " 'rwrr+31000.csv',\n",
       " 'rwrr+33000.csv',\n",
       " 'rwrr+35000.csv',\n",
       " 'rwrr+37000.csv',\n",
       " 'rwrr+39000.csv',\n",
       " 'rwrr+40000.csv',\n",
       " 'rwrr+5000.csv',\n",
       " 'rwrr+7000.csv',\n",
       " 'rwrr+9000.csv',\n",
       " 'rwrr-1000.csv',\n",
       " 'rwrr-10000.csv',\n",
       " 'rwrr-11000.csv',\n",
       " 'rwrr-13000.csv',\n",
       " 'rwrr-15000.csv',\n",
       " 'rwrr-17000.csv',\n",
       " 'rwrr-19000.csv',\n",
       " 'rwrr-20000.csv',\n",
       " 'rwrr-21000.csv',\n",
       " 'rwrr-23000.csv',\n",
       " 'rwrr-2500.csv',\n",
       " 'rwrr-25000.csv',\n",
       " 'rwrr-27000.csv',\n",
       " 'rwrr-29000.csv',\n",
       " 'rwrr-3000.csv',\n",
       " 'rwrr-31000.csv',\n",
       " 'rwrr-33000.csv',\n",
       " 'rwrr-35000.csv',\n",
       " 'rwrr-37000.csv',\n",
       " 'rwrr-39000.csv',\n",
       " 'rwrr-40000.csv',\n",
       " 'rwrr-5000.csv',\n",
       " 'rwrr-7000.csv',\n",
       " 'rwrr-9000.csv',\n",
       " 'rwrr.csv',\n",
       " 'rwrr1.csv']"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.ndarray((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.89877641e-310,   6.89877641e-310,   6.89877641e-310,\n",
       "         6.89877641e-310,   6.89877641e-310,   6.89884666e-310,\n",
       "         6.89884666e-310,   6.89884157e-310,   6.89878197e-310,\n",
       "         6.89878197e-310])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.628124, 0.698651, 0.450611, 0.547864, 0.663138\n",
      "xgb                       : 0.901374, 0.919547, 0.879715, 0.899190, 0.953005\n",
      "logistic                  : 0.886125, 0.896173, 0.873445, 0.884663, 0.928207\n",
      "random forest             : 0.891552, 0.897304, 0.884314, 0.890762, 0.939377\n",
      "naive bayes               : 0.558723, 0.811743, 0.152908, 0.257341, 0.721241\n",
      "NB+CP\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.629335, 0.700651, 0.451622, 0.549227, 0.665721\n",
      "xgb                       : 0.912535, 0.931733, 0.890301, 0.910546, 0.962462\n",
      "logistic                  : 0.910752, 0.930316, 0.888020, 0.908676, 0.947008\n",
      "random forest             : 0.901673, 0.916834, 0.883488, 0.899852, 0.946551\n",
      "naive bayes               : 0.558723, 0.811743, 0.152908, 0.257341, 0.721323\n",
      "NB+CP+LP\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.729808, 0.775341, 0.647125, 0.705454, 0.785428\n",
      "xgb                       : 0.913077, 0.931378, 0.891865, 0.911193, 0.963872\n",
      "logistic                  : 0.910968, 0.930217, 0.888598, 0.908931, 0.948055\n",
      "random forest             : 0.903180, 0.917516, 0.886012, 0.901489, 0.950030\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780896\n",
      "NB+CP+LP+LSP\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.730882, 0.776901, 0.647786, 0.706493, 0.786836\n",
      "xgb                       : 0.913402, 0.932337, 0.891503, 0.911463, 0.963982\n",
      "logistic                  : 0.910808, 0.931785, 0.886518, 0.908588, 0.949322\n",
      "random forest             : 0.903753, 0.918011, 0.886698, 0.902083, 0.950368\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780937\n",
      "NB+CP+LP+LSP+RWR\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.730882, 0.776901, 0.647786, 0.706493, 0.786830\n",
      "xgb                       : 0.913655, 0.933444, 0.890827, 0.911638, 0.964569\n",
      "logistic                  : 0.912891, 0.929360, 0.893712, 0.911188, 0.961864\n",
      "random forest             : 0.904620, 0.921377, 0.884737, 0.902685, 0.950910\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780937\n",
      "NB+CP+LP+LSP+RWR+RWRR\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.730882, 0.776901, 0.647786, 0.706493, 0.786830\n",
      "xgb                       : 0.913670, 0.932917, 0.891441, 0.911708, 0.964646\n",
      "logistic                  : 0.912924, 0.929300, 0.893852, 0.911231, 0.962136\n",
      "random forest             : 0.904641, 0.921113, 0.885083, 0.902739, 0.951161\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780937\n"
     ]
    }
   ],
   "source": [
    "Eval = pd.DataFrame()\n",
    "sim_data = {\n",
    "    'cp': [cp1, cp2],\n",
    "    'lp': [lp1, lp2],\n",
    "    'lsp': [lsp1, lsp2],\n",
    "    'rwr': [rwr1, rwr2],\n",
    "    'rwrr': [rwrr1, rwrr2]\n",
    "}\n",
    "comb_name = 'NB'\n",
    "ytrain = nb_data1['link'].values\n",
    "ytest = nb_data2['link'].values\n",
    "xtrain = nb1\n",
    "xtest = nb2\n",
    "eval_df = train_eval()\n",
    "Eval = Eval.append(pd.concat([pd.Series([comb_name]*5, name='Methods'), eval_df], axis=1))\n",
    "for name in ['cp', 'lp', 'lsp', 'rwr', 'rwrr']:\n",
    "    comb_name += '+' + name.upper()\n",
    "    print(comb_name)\n",
    "    train, test = sim_data[name]\n",
    "    xtrain = np.hstack([xtrain, train])\n",
    "    xtest = np.hstack([xtest, test])\n",
    "    eval_df = train_eval()\n",
    "    Eval = Eval.append(pd.concat([pd.Series([comb_name]*5, name='Methods'), eval_df], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval.to_csv('./output/modelresult2/feature_comb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.628124</td>\n",
       "      <td>0.698651</td>\n",
       "      <td>0.450611</td>\n",
       "      <td>0.547864</td>\n",
       "      <td>0.663138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.901374</td>\n",
       "      <td>0.919547</td>\n",
       "      <td>0.879715</td>\n",
       "      <td>0.899190</td>\n",
       "      <td>0.953005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.886125</td>\n",
       "      <td>0.896173</td>\n",
       "      <td>0.873445</td>\n",
       "      <td>0.884663</td>\n",
       "      <td>0.928207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.891552</td>\n",
       "      <td>0.897304</td>\n",
       "      <td>0.884314</td>\n",
       "      <td>0.890762</td>\n",
       "      <td>0.939377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.558723</td>\n",
       "      <td>0.811743</td>\n",
       "      <td>0.152908</td>\n",
       "      <td>0.257341</td>\n",
       "      <td>0.721241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.629335</td>\n",
       "      <td>0.700651</td>\n",
       "      <td>0.451622</td>\n",
       "      <td>0.549227</td>\n",
       "      <td>0.665721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.912535</td>\n",
       "      <td>0.931733</td>\n",
       "      <td>0.890301</td>\n",
       "      <td>0.910546</td>\n",
       "      <td>0.962462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.910752</td>\n",
       "      <td>0.930316</td>\n",
       "      <td>0.888020</td>\n",
       "      <td>0.908676</td>\n",
       "      <td>0.947008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.901673</td>\n",
       "      <td>0.916834</td>\n",
       "      <td>0.883488</td>\n",
       "      <td>0.899852</td>\n",
       "      <td>0.946551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.558723</td>\n",
       "      <td>0.811743</td>\n",
       "      <td>0.152908</td>\n",
       "      <td>0.257341</td>\n",
       "      <td>0.721323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.729808</td>\n",
       "      <td>0.775341</td>\n",
       "      <td>0.647125</td>\n",
       "      <td>0.705454</td>\n",
       "      <td>0.785428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913077</td>\n",
       "      <td>0.931378</td>\n",
       "      <td>0.891865</td>\n",
       "      <td>0.911193</td>\n",
       "      <td>0.963872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.910968</td>\n",
       "      <td>0.930217</td>\n",
       "      <td>0.888598</td>\n",
       "      <td>0.908931</td>\n",
       "      <td>0.948055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.903180</td>\n",
       "      <td>0.917516</td>\n",
       "      <td>0.886012</td>\n",
       "      <td>0.901489</td>\n",
       "      <td>0.950030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LP+LSP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.647786</td>\n",
       "      <td>0.706493</td>\n",
       "      <td>0.786836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LP+LSP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913402</td>\n",
       "      <td>0.932337</td>\n",
       "      <td>0.891503</td>\n",
       "      <td>0.911463</td>\n",
       "      <td>0.963982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LP+LSP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.910808</td>\n",
       "      <td>0.931785</td>\n",
       "      <td>0.886518</td>\n",
       "      <td>0.908588</td>\n",
       "      <td>0.949322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LP+LSP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.903753</td>\n",
       "      <td>0.918011</td>\n",
       "      <td>0.886698</td>\n",
       "      <td>0.902083</td>\n",
       "      <td>0.950368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LP+LSP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.647786</td>\n",
       "      <td>0.706493</td>\n",
       "      <td>0.786830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.933444</td>\n",
       "      <td>0.890827</td>\n",
       "      <td>0.911638</td>\n",
       "      <td>0.964569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.912891</td>\n",
       "      <td>0.929360</td>\n",
       "      <td>0.893712</td>\n",
       "      <td>0.911188</td>\n",
       "      <td>0.961864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.904620</td>\n",
       "      <td>0.921377</td>\n",
       "      <td>0.884737</td>\n",
       "      <td>0.902685</td>\n",
       "      <td>0.950910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.647786</td>\n",
       "      <td>0.706493</td>\n",
       "      <td>0.786830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913670</td>\n",
       "      <td>0.932917</td>\n",
       "      <td>0.891441</td>\n",
       "      <td>0.911708</td>\n",
       "      <td>0.964646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.912924</td>\n",
       "      <td>0.929300</td>\n",
       "      <td>0.893852</td>\n",
       "      <td>0.911231</td>\n",
       "      <td>0.962136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.904641</td>\n",
       "      <td>0.921113</td>\n",
       "      <td>0.885083</td>\n",
       "      <td>0.902739</td>\n",
       "      <td>0.951161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Methods          model  accuracy  precision    recall  \\\n",
       "0                     NB            knn  0.628124   0.698651  0.450611   \n",
       "1                     NB            xgb  0.901374   0.919547  0.879715   \n",
       "2                     NB       logistic  0.886125   0.896173  0.873445   \n",
       "3                     NB  random forest  0.891552   0.897304  0.884314   \n",
       "4                     NB    naive bayes  0.558723   0.811743  0.152908   \n",
       "0                  NB+CP            knn  0.629335   0.700651  0.451622   \n",
       "1                  NB+CP            xgb  0.912535   0.931733  0.890301   \n",
       "2                  NB+CP       logistic  0.910752   0.930316  0.888020   \n",
       "3                  NB+CP  random forest  0.901673   0.916834  0.883488   \n",
       "4                  NB+CP    naive bayes  0.558723   0.811743  0.152908   \n",
       "0               NB+CP+LP            knn  0.729808   0.775341  0.647125   \n",
       "1               NB+CP+LP            xgb  0.913077   0.931378  0.891865   \n",
       "2               NB+CP+LP       logistic  0.910968   0.930217  0.888598   \n",
       "3               NB+CP+LP  random forest  0.903180   0.917516  0.886012   \n",
       "4               NB+CP+LP    naive bayes  0.562109   0.813190  0.161264   \n",
       "0           NB+CP+LP+LSP            knn  0.730882   0.776901  0.647786   \n",
       "1           NB+CP+LP+LSP            xgb  0.913402   0.932337  0.891503   \n",
       "2           NB+CP+LP+LSP       logistic  0.910808   0.931785  0.886518   \n",
       "3           NB+CP+LP+LSP  random forest  0.903753   0.918011  0.886698   \n",
       "4           NB+CP+LP+LSP    naive bayes  0.562109   0.813190  0.161264   \n",
       "0       NB+CP+LP+LSP+RWR            knn  0.730882   0.776901  0.647786   \n",
       "1       NB+CP+LP+LSP+RWR            xgb  0.913655   0.933444  0.890827   \n",
       "2       NB+CP+LP+LSP+RWR       logistic  0.912891   0.929360  0.893712   \n",
       "3       NB+CP+LP+LSP+RWR  random forest  0.904620   0.921377  0.884737   \n",
       "4       NB+CP+LP+LSP+RWR    naive bayes  0.562109   0.813190  0.161264   \n",
       "0  NB+CP+LP+LSP+RWR+RWRR            knn  0.730882   0.776901  0.647786   \n",
       "1  NB+CP+LP+LSP+RWR+RWRR            xgb  0.913670   0.932917  0.891441   \n",
       "2  NB+CP+LP+LSP+RWR+RWRR       logistic  0.912924   0.929300  0.893852   \n",
       "3  NB+CP+LP+LSP+RWR+RWRR  random forest  0.904641   0.921113  0.885083   \n",
       "4  NB+CP+LP+LSP+RWR+RWRR    naive bayes  0.562109   0.813190  0.161264   \n",
       "\n",
       "         f1       auc  \n",
       "0  0.547864  0.663138  \n",
       "1  0.899190  0.953005  \n",
       "2  0.884663  0.928207  \n",
       "3  0.890762  0.939377  \n",
       "4  0.257341  0.721241  \n",
       "0  0.549227  0.665721  \n",
       "1  0.910546  0.962462  \n",
       "2  0.908676  0.947008  \n",
       "3  0.899852  0.946551  \n",
       "4  0.257341  0.721323  \n",
       "0  0.705454  0.785428  \n",
       "1  0.911193  0.963872  \n",
       "2  0.908931  0.948055  \n",
       "3  0.901489  0.950030  \n",
       "4  0.269152  0.780896  \n",
       "0  0.706493  0.786836  \n",
       "1  0.911463  0.963982  \n",
       "2  0.908588  0.949322  \n",
       "3  0.902083  0.950368  \n",
       "4  0.269152  0.780937  \n",
       "0  0.706493  0.786830  \n",
       "1  0.911638  0.964569  \n",
       "2  0.911188  0.961864  \n",
       "3  0.902685  0.950910  \n",
       "4  0.269152  0.780937  \n",
       "0  0.706493  0.786830  \n",
       "1  0.911708  0.964646  \n",
       "2  0.911231  0.962136  \n",
       "3  0.902739  0.951161  \n",
       "4  0.269152  0.780937  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb',\n",
       " 'nb+cp',\n",
       " 'nb+cp+lp',\n",
       " 'nb+cp+lp+lsp+rwr',\n",
       " 'nb+cp+lp+lsp+rwr+rwrr',\n",
       " 'nb+cp+lp+lsp+rwrr',\n",
       " 'nb+cp+lsp',\n",
       " 'nb+lp+rwr']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sim_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.628124, 0.698651, 0.450611, 0.547864, 0.663138\n",
      "xgb                       : 0.901374, 0.919547, 0.879715, 0.899190, 0.953005\n",
      "logistic                  : 0.886007, 0.894759, 0.874921, 0.884729, 0.929368\n",
      "random forest             : 0.891552, 0.897304, 0.884314, 0.890762, 0.939377\n",
      "naive bayes               : 0.558723, 0.811743, 0.152908, 0.257341, 0.721241\n",
      "nb+cp\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.629335, 0.700651, 0.451622, 0.549227, 0.665721\n",
      "xgb                       : 0.912535, 0.931733, 0.890301, 0.910546, 0.962462\n",
      "logistic                  : 0.910566, 0.930116, 0.887839, 0.908486, 0.946847\n",
      "random forest             : 0.901673, 0.916834, 0.883488, 0.899852, 0.946551\n",
      "naive bayes               : 0.558723, 0.811743, 0.152908, 0.257341, 0.721323\n",
      "nb+cp+lp\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.729808, 0.775341, 0.647125, 0.705454, 0.785428\n",
      "xgb                       : 0.913077, 0.931378, 0.891865, 0.911193, 0.963872\n",
      "logistic                  : 0.911404, 0.929821, 0.889981, 0.909465, 0.948296\n",
      "random forest             : 0.903180, 0.917516, 0.886012, 0.901489, 0.950030\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780896\n",
      "nb+cp+lsp\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.632011, 0.704431, 0.454884, 0.552800, 0.670034\n",
      "xgb                       : 0.913410, 0.932399, 0.891452, 0.911466, 0.963807\n",
      "logistic                  : 0.909456, 0.933136, 0.882120, 0.906912, 0.949016\n",
      "random forest             : 0.904259, 0.918267, 0.887514, 0.902628, 0.951350\n",
      "naive bayes               : 0.558723, 0.811743, 0.152908, 0.257341, 0.721569\n",
      "nb+cp+lp+lsp+rwr\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.730882, 0.776901, 0.647786, 0.706493, 0.786830\n",
      "xgb                       : 0.913655, 0.933444, 0.890827, 0.911638, 0.964569\n",
      "logistic                  : 0.912896, 0.929356, 0.893728, 0.911194, 0.961877\n",
      "random forest             : 0.904620, 0.921377, 0.884737, 0.902685, 0.950910\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780937\n",
      "nb+cp+lp+lsp+rwrr\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.730882, 0.776901, 0.647786, 0.706493, 0.786836\n",
      "xgb                       : 0.913417, 0.930795, 0.893248, 0.911635, 0.964785\n",
      "logistic                  : 0.910723, 0.929591, 0.888763, 0.908719, 0.954158\n",
      "random forest             : 0.903356, 0.919640, 0.883953, 0.901443, 0.950968\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780937\n",
      "nb+lp+rwr\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.729383, 0.774839, 0.646686, 0.704986, 0.784778\n",
      "xgb                       : 0.913425, 0.932761, 0.891085, 0.911447, 0.964466\n",
      "logistic                  : 0.908700, 0.920962, 0.894135, 0.907351, 0.954142\n",
      "random forest             : 0.902930, 0.918171, 0.884706, 0.901128, 0.950357\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780882\n",
      "nb+cp+lp+lsp+rwr+rwrr\n",
      "Fitting models.\n",
      "knn... done\n",
      "xgb... done\n",
      "logistic... done\n",
      "random forest... done\n",
      "naive bayes... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "knn                       : 0.730882, 0.776901, 0.647786, 0.706493, 0.786830\n",
      "xgb                       : 0.913670, 0.932917, 0.891441, 0.911708, 0.964646\n",
      "logistic                  : 0.912899, 0.929361, 0.893728, 0.911196, 0.961842\n",
      "random forest             : 0.904641, 0.921113, 0.885083, 0.902739, 0.951161\n",
      "naive bayes               : 0.562109, 0.813190, 0.161264, 0.269152, 0.780937\n"
     ]
    }
   ],
   "source": [
    "Eval = pd.DataFrame()\n",
    "sim_data = {\n",
    "    'nb': [nb1, nb2],\n",
    "    'nb+cp': [np.hstack([nb1, cp1]), np.hstack([nb2, cp2])],\n",
    "    'nb+cp+lp': [np.hstack([nb1, cp1, lp1]), np.hstack([nb2, cp2, lp2])],\n",
    "    'nb+cp+lsp': [np.hstack([nb1, cp1, lsp1]), np.hstack([nb2, cp2, lsp2])],\n",
    "    'nb+cp+lp+lsp+rwr': [np.hstack([nb1, cp1, lp1, lsp1, rwr1]), np.hstack([nb2, cp2, lp2, lsp2, rwr2])],\n",
    "    'nb+cp+lp+lsp+rwrr': [np.hstack([nb1, cp1, lp1, lsp1, rwrr1]), np.hstack([nb2, cp2, lp2, lsp2, rwrr2])],\n",
    "    'nb+lp+rwr': [np.hstack([nb1, lp1, rwr1]), np.hstack([nb2, lp2, rwr2])],\n",
    "    'nb+cp+lp+lsp+rwr+rwrr': [np.hstack([nb1, cp1, lp1, lsp1, rwr1, rwrr1]), np.hstack([nb2, cp2, lp2, lsp2, rwr2, rwrr2])],\n",
    "}\n",
    "ytrain = nb_data1['link'].values\n",
    "ytest = nb_data2['link'].values\n",
    "for name in ['nb', 'nb+cp', 'nb+cp+lp', 'nb+cp+lsp', 'nb+cp+lp+lsp+rwr', 'nb+cp+lp+lsp+rwrr',\n",
    " 'nb+lp+rwr', 'nb+cp+lp+lsp+rwr+rwrr']: \n",
    "    print(name)\n",
    "    xtrain, xtest = sim_data[name]\n",
    "    eval_df = train_eval()\n",
    "    Eval = Eval.append(pd.concat([pd.Series([name.upper()]*5, name='Methods'), eval_df], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eval.to_csv('./output/modelresult2/feature_comb2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.628124</td>\n",
       "      <td>0.698651</td>\n",
       "      <td>0.450611</td>\n",
       "      <td>0.547864</td>\n",
       "      <td>0.663138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.901374</td>\n",
       "      <td>0.919547</td>\n",
       "      <td>0.879715</td>\n",
       "      <td>0.899190</td>\n",
       "      <td>0.953005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.886007</td>\n",
       "      <td>0.894759</td>\n",
       "      <td>0.874921</td>\n",
       "      <td>0.884729</td>\n",
       "      <td>0.929368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.891552</td>\n",
       "      <td>0.897304</td>\n",
       "      <td>0.884314</td>\n",
       "      <td>0.890762</td>\n",
       "      <td>0.939377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.558723</td>\n",
       "      <td>0.811743</td>\n",
       "      <td>0.152908</td>\n",
       "      <td>0.257341</td>\n",
       "      <td>0.721241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.629335</td>\n",
       "      <td>0.700651</td>\n",
       "      <td>0.451622</td>\n",
       "      <td>0.549227</td>\n",
       "      <td>0.665721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.912535</td>\n",
       "      <td>0.931733</td>\n",
       "      <td>0.890301</td>\n",
       "      <td>0.910546</td>\n",
       "      <td>0.962462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.910566</td>\n",
       "      <td>0.930116</td>\n",
       "      <td>0.887839</td>\n",
       "      <td>0.908486</td>\n",
       "      <td>0.946847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.901673</td>\n",
       "      <td>0.916834</td>\n",
       "      <td>0.883488</td>\n",
       "      <td>0.899852</td>\n",
       "      <td>0.946551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.558723</td>\n",
       "      <td>0.811743</td>\n",
       "      <td>0.152908</td>\n",
       "      <td>0.257341</td>\n",
       "      <td>0.721323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.729808</td>\n",
       "      <td>0.775341</td>\n",
       "      <td>0.647125</td>\n",
       "      <td>0.705454</td>\n",
       "      <td>0.785428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913077</td>\n",
       "      <td>0.931378</td>\n",
       "      <td>0.891865</td>\n",
       "      <td>0.911193</td>\n",
       "      <td>0.963872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.911404</td>\n",
       "      <td>0.929821</td>\n",
       "      <td>0.889981</td>\n",
       "      <td>0.909465</td>\n",
       "      <td>0.948296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.903180</td>\n",
       "      <td>0.917516</td>\n",
       "      <td>0.886012</td>\n",
       "      <td>0.901489</td>\n",
       "      <td>0.950030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LSP</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.632011</td>\n",
       "      <td>0.704431</td>\n",
       "      <td>0.454884</td>\n",
       "      <td>0.552800</td>\n",
       "      <td>0.670034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LSP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913410</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.891452</td>\n",
       "      <td>0.911466</td>\n",
       "      <td>0.963807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LSP</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.909456</td>\n",
       "      <td>0.933136</td>\n",
       "      <td>0.882120</td>\n",
       "      <td>0.906912</td>\n",
       "      <td>0.949016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LSP</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.904259</td>\n",
       "      <td>0.918267</td>\n",
       "      <td>0.887514</td>\n",
       "      <td>0.902628</td>\n",
       "      <td>0.951350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LSP</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.558723</td>\n",
       "      <td>0.811743</td>\n",
       "      <td>0.152908</td>\n",
       "      <td>0.257341</td>\n",
       "      <td>0.721569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.647786</td>\n",
       "      <td>0.706493</td>\n",
       "      <td>0.786830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.933444</td>\n",
       "      <td>0.890827</td>\n",
       "      <td>0.911638</td>\n",
       "      <td>0.964569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.912896</td>\n",
       "      <td>0.929356</td>\n",
       "      <td>0.893728</td>\n",
       "      <td>0.911194</td>\n",
       "      <td>0.961877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.904620</td>\n",
       "      <td>0.921377</td>\n",
       "      <td>0.884737</td>\n",
       "      <td>0.902685</td>\n",
       "      <td>0.950910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LP+LSP+RWRR</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.647786</td>\n",
       "      <td>0.706493</td>\n",
       "      <td>0.786836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LP+LSP+RWRR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913417</td>\n",
       "      <td>0.930795</td>\n",
       "      <td>0.893248</td>\n",
       "      <td>0.911635</td>\n",
       "      <td>0.964785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LP+LSP+RWRR</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.910723</td>\n",
       "      <td>0.929591</td>\n",
       "      <td>0.888763</td>\n",
       "      <td>0.908719</td>\n",
       "      <td>0.954158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LP+LSP+RWRR</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.903356</td>\n",
       "      <td>0.919640</td>\n",
       "      <td>0.883953</td>\n",
       "      <td>0.901443</td>\n",
       "      <td>0.950968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LP+LSP+RWRR</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+LP+RWR</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.729383</td>\n",
       "      <td>0.774839</td>\n",
       "      <td>0.646686</td>\n",
       "      <td>0.704986</td>\n",
       "      <td>0.784778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+LP+RWR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913425</td>\n",
       "      <td>0.932761</td>\n",
       "      <td>0.891085</td>\n",
       "      <td>0.911447</td>\n",
       "      <td>0.964466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+LP+RWR</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.908700</td>\n",
       "      <td>0.920962</td>\n",
       "      <td>0.894135</td>\n",
       "      <td>0.907351</td>\n",
       "      <td>0.954142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+LP+RWR</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.902930</td>\n",
       "      <td>0.918171</td>\n",
       "      <td>0.884706</td>\n",
       "      <td>0.901128</td>\n",
       "      <td>0.950357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+LP+RWR</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.776901</td>\n",
       "      <td>0.647786</td>\n",
       "      <td>0.706493</td>\n",
       "      <td>0.786830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913670</td>\n",
       "      <td>0.932917</td>\n",
       "      <td>0.891441</td>\n",
       "      <td>0.911708</td>\n",
       "      <td>0.964646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>logistic</td>\n",
       "      <td>0.912899</td>\n",
       "      <td>0.929361</td>\n",
       "      <td>0.893728</td>\n",
       "      <td>0.911196</td>\n",
       "      <td>0.961842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>random forest</td>\n",
       "      <td>0.904641</td>\n",
       "      <td>0.921113</td>\n",
       "      <td>0.885083</td>\n",
       "      <td>0.902739</td>\n",
       "      <td>0.951161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>naive bayes</td>\n",
       "      <td>0.562109</td>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.780937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Methods          model  accuracy  precision    recall  \\\n",
       "0                     NB            knn  0.628124   0.698651  0.450611   \n",
       "1                     NB            xgb  0.901374   0.919547  0.879715   \n",
       "2                     NB       logistic  0.886007   0.894759  0.874921   \n",
       "3                     NB  random forest  0.891552   0.897304  0.884314   \n",
       "4                     NB    naive bayes  0.558723   0.811743  0.152908   \n",
       "0                  NB+CP            knn  0.629335   0.700651  0.451622   \n",
       "1                  NB+CP            xgb  0.912535   0.931733  0.890301   \n",
       "2                  NB+CP       logistic  0.910566   0.930116  0.887839   \n",
       "3                  NB+CP  random forest  0.901673   0.916834  0.883488   \n",
       "4                  NB+CP    naive bayes  0.558723   0.811743  0.152908   \n",
       "0               NB+CP+LP            knn  0.729808   0.775341  0.647125   \n",
       "1               NB+CP+LP            xgb  0.913077   0.931378  0.891865   \n",
       "2               NB+CP+LP       logistic  0.911404   0.929821  0.889981   \n",
       "3               NB+CP+LP  random forest  0.903180   0.917516  0.886012   \n",
       "4               NB+CP+LP    naive bayes  0.562109   0.813190  0.161264   \n",
       "0              NB+CP+LSP            knn  0.632011   0.704431  0.454884   \n",
       "1              NB+CP+LSP            xgb  0.913410   0.932399  0.891452   \n",
       "2              NB+CP+LSP       logistic  0.909456   0.933136  0.882120   \n",
       "3              NB+CP+LSP  random forest  0.904259   0.918267  0.887514   \n",
       "4              NB+CP+LSP    naive bayes  0.558723   0.811743  0.152908   \n",
       "0       NB+CP+LP+LSP+RWR            knn  0.730882   0.776901  0.647786   \n",
       "1       NB+CP+LP+LSP+RWR            xgb  0.913655   0.933444  0.890827   \n",
       "2       NB+CP+LP+LSP+RWR       logistic  0.912896   0.929356  0.893728   \n",
       "3       NB+CP+LP+LSP+RWR  random forest  0.904620   0.921377  0.884737   \n",
       "4       NB+CP+LP+LSP+RWR    naive bayes  0.562109   0.813190  0.161264   \n",
       "0      NB+CP+LP+LSP+RWRR            knn  0.730882   0.776901  0.647786   \n",
       "1      NB+CP+LP+LSP+RWRR            xgb  0.913417   0.930795  0.893248   \n",
       "2      NB+CP+LP+LSP+RWRR       logistic  0.910723   0.929591  0.888763   \n",
       "3      NB+CP+LP+LSP+RWRR  random forest  0.903356   0.919640  0.883953   \n",
       "4      NB+CP+LP+LSP+RWRR    naive bayes  0.562109   0.813190  0.161264   \n",
       "0              NB+LP+RWR            knn  0.729383   0.774839  0.646686   \n",
       "1              NB+LP+RWR            xgb  0.913425   0.932761  0.891085   \n",
       "2              NB+LP+RWR       logistic  0.908700   0.920962  0.894135   \n",
       "3              NB+LP+RWR  random forest  0.902930   0.918171  0.884706   \n",
       "4              NB+LP+RWR    naive bayes  0.562109   0.813190  0.161264   \n",
       "0  NB+CP+LP+LSP+RWR+RWRR            knn  0.730882   0.776901  0.647786   \n",
       "1  NB+CP+LP+LSP+RWR+RWRR            xgb  0.913670   0.932917  0.891441   \n",
       "2  NB+CP+LP+LSP+RWR+RWRR       logistic  0.912899   0.929361  0.893728   \n",
       "3  NB+CP+LP+LSP+RWR+RWRR  random forest  0.904641   0.921113  0.885083   \n",
       "4  NB+CP+LP+LSP+RWR+RWRR    naive bayes  0.562109   0.813190  0.161264   \n",
       "\n",
       "         f1       auc  \n",
       "0  0.547864  0.663138  \n",
       "1  0.899190  0.953005  \n",
       "2  0.884729  0.929368  \n",
       "3  0.890762  0.939377  \n",
       "4  0.257341  0.721241  \n",
       "0  0.549227  0.665721  \n",
       "1  0.910546  0.962462  \n",
       "2  0.908486  0.946847  \n",
       "3  0.899852  0.946551  \n",
       "4  0.257341  0.721323  \n",
       "0  0.705454  0.785428  \n",
       "1  0.911193  0.963872  \n",
       "2  0.909465  0.948296  \n",
       "3  0.901489  0.950030  \n",
       "4  0.269152  0.780896  \n",
       "0  0.552800  0.670034  \n",
       "1  0.911466  0.963807  \n",
       "2  0.906912  0.949016  \n",
       "3  0.902628  0.951350  \n",
       "4  0.257341  0.721569  \n",
       "0  0.706493  0.786830  \n",
       "1  0.911638  0.964569  \n",
       "2  0.911194  0.961877  \n",
       "3  0.902685  0.950910  \n",
       "4  0.269152  0.780937  \n",
       "0  0.706493  0.786836  \n",
       "1  0.911635  0.964785  \n",
       "2  0.908719  0.954158  \n",
       "3  0.901443  0.950968  \n",
       "4  0.269152  0.780937  \n",
       "0  0.704986  0.784778  \n",
       "1  0.911447  0.964466  \n",
       "2  0.907351  0.954142  \n",
       "3  0.901128  0.950357  \n",
       "4  0.269152  0.780882  \n",
       "0  0.706493  0.786830  \n",
       "1  0.911708  0.964646  \n",
       "2  0.911196  0.961842  \n",
       "3  0.902739  0.951161  \n",
       "4  0.269152  0.780937  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.901374</td>\n",
       "      <td>0.919547</td>\n",
       "      <td>0.879715</td>\n",
       "      <td>0.899190</td>\n",
       "      <td>0.953005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NB+CP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.912535</td>\n",
       "      <td>0.931733</td>\n",
       "      <td>0.890301</td>\n",
       "      <td>0.910546</td>\n",
       "      <td>0.962462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NB+CP+LP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913077</td>\n",
       "      <td>0.931378</td>\n",
       "      <td>0.891865</td>\n",
       "      <td>0.911193</td>\n",
       "      <td>0.963872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NB+CP+LSP</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913410</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.891452</td>\n",
       "      <td>0.911466</td>\n",
       "      <td>0.963807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NB+CP+LP+LSP+RWR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913655</td>\n",
       "      <td>0.933444</td>\n",
       "      <td>0.890827</td>\n",
       "      <td>0.911638</td>\n",
       "      <td>0.964569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NB+CP+LP+LSP+RWRR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913417</td>\n",
       "      <td>0.930795</td>\n",
       "      <td>0.893248</td>\n",
       "      <td>0.911635</td>\n",
       "      <td>0.964785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NB+LP+RWR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913425</td>\n",
       "      <td>0.932761</td>\n",
       "      <td>0.891085</td>\n",
       "      <td>0.911447</td>\n",
       "      <td>0.964466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NB+CP+LP+LSP+RWR+RWRR</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.913670</td>\n",
       "      <td>0.932917</td>\n",
       "      <td>0.891441</td>\n",
       "      <td>0.911708</td>\n",
       "      <td>0.964646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Methods model  accuracy  precision    recall        f1  \\\n",
       "1                      NB   xgb  0.901374   0.919547  0.879715  0.899190   \n",
       "6                   NB+CP   xgb  0.912535   0.931733  0.890301  0.910546   \n",
       "11               NB+CP+LP   xgb  0.913077   0.931378  0.891865  0.911193   \n",
       "16              NB+CP+LSP   xgb  0.913410   0.932399  0.891452  0.911466   \n",
       "21       NB+CP+LP+LSP+RWR   xgb  0.913655   0.933444  0.890827  0.911638   \n",
       "26      NB+CP+LP+LSP+RWRR   xgb  0.913417   0.930795  0.893248  0.911635   \n",
       "31              NB+LP+RWR   xgb  0.913425   0.932761  0.891085  0.911447   \n",
       "36  NB+CP+LP+LSP+RWR+RWRR   xgb  0.913670   0.932917  0.891441  0.911708   \n",
       "\n",
       "         auc  \n",
       "1   0.953005  \n",
       "6   0.962462  \n",
       "11  0.963872  \n",
       "16  0.963807  \n",
       "21  0.964569  \n",
       "26  0.964785  \n",
       "31  0.964466  \n",
       "36  0.964646  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval = pd.read_csv('./output/modelresult2/feature_comb2.csv')\n",
    "Eval.loc[Eval['model']=='xgb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 数据整体分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1=pd.read_csv('./input/data0117.csv',encoding='gbk',usecols=['id','app'])\n",
    "data2=pd.read_csv('./input/data0118.csv',encoding='gbk',usecols=['id','app'])\n",
    "data3=pd.read_csv('./input/data0119.csv',encoding='gbk',usecols=['id','app'])\n",
    "data4=pd.read_csv('./input/data0120.csv',encoding='gbk',usecols=['id','app'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_edges(data):\n",
    "    groups = data.groupby(['id','app']).groups\n",
    "    edges = {g for g in groups}   \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges1 = get_edges(data1)\n",
    "edges2 = get_edges(data2)\n",
    "edges3 = get_edges(data3)\n",
    "edges4 = get_edges(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13821558758402105, 152019, 41167, 38221)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每天的边，密度， 连续出现的边， 消失的边， 衍生的边\n",
    "len(edges1)/float(25413*55),len(edges1), len(edges1 & edges2), len(edges1 - (edges1 & edges2)), len(edges2 - (edges1 & edges2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 每天的边，密度， 连续出现不变的边， 不变率\n",
    "def graph_describe(edges1, edges2):\n",
    "    return len(edges1), len(edges1)/float(25413*55), len(edges1 & edges2), len(edges1 & edges2)/float(len(edges1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = np.zeros([3, 4])\n",
    "des = graph_describe(edges1, edges2)\n",
    "description[0, :] = des\n",
    "des = graph_describe(edges2, edges3)\n",
    "description[1, :] = des\n",
    "des = graph_describe(edges3, edges4)\n",
    "description[2, :] = des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    192394.333333\n",
       "1         0.137649\n",
       "2    152357.333333\n",
       "3         0.791966\n",
       "dtype: float64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(description).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小结：所以precision一定要大于79%才能说明系统有效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apps_of_user(edges):\n",
    "    user_apps = dict()\n",
    "    for edge in edges:\n",
    "        user, app = edge\n",
    "        user_apps.setdefault(user, set())\n",
    "        user_apps[user].add(app)\n",
    "    return user_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_apps1 = get_apps_of_user(edges1)\n",
    "user_apps2 = get_apps_of_user(edges2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24009\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for user in user_apps1.keys():\n",
    "    if user_apps1[user] != user_apps2[user]:\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447526856333373"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24009/25413.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17517\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for user in user_apps1.keys():\n",
    "    if (user_apps2[user]-user_apps1[user]):\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892928815960335"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17517/25413.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Keep',\n",
       " 'QQ',\n",
       " '大众点评网',\n",
       " '开心消消乐',\n",
       " '微信',\n",
       " '搜狗输入法',\n",
       " '支付宝',\n",
       " '新浪微博',\n",
       " '百度地图',\n",
       " '百度搜索',\n",
       " '美颜相机',\n",
       " '腾讯视频'}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_apps1[list(user_apps.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={1}\n",
    "a.add(2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>app</th>\n",
       "      <th>app_cat</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E0A0D252AB03C498807BFA8CEE739FB6</td>\n",
       "      <td>17</td>\n",
       "      <td>微信</td>\n",
       "      <td>通讯聊天</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FB80F10790E7D793E46918CB0720E91E</td>\n",
       "      <td>10</td>\n",
       "      <td>微信</td>\n",
       "      <td>通讯聊天</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C876D14B19676A576E84C5D1953CFE9B</td>\n",
       "      <td>19</td>\n",
       "      <td>微信</td>\n",
       "      <td>通讯聊天</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CCDA8CF84778FE5F15725D1F1BA46F52</td>\n",
       "      <td>15</td>\n",
       "      <td>腾讯视频</td>\n",
       "      <td>视频服务</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E1A0CF5C94706D3686452D8BBDCC3BC3</td>\n",
       "      <td>7</td>\n",
       "      <td>QQ</td>\n",
       "      <td>通讯聊天</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  hour   app app_cat  times\n",
       "0           0  E0A0D252AB03C498807BFA8CEE739FB6    17    微信    通讯聊天     20\n",
       "1           1  FB80F10790E7D793E46918CB0720E91E    10    微信    通讯聊天      2\n",
       "2           2  C876D14B19676A576E84C5D1953CFE9B    19    微信    通讯聊天    280\n",
       "3           3  CCDA8CF84778FE5F15725D1F1BA46F52    15  腾讯视频    视频服务     22\n",
       "4           4  E1A0CF5C94706D3686452D8BBDCC3BC3     7    QQ    通讯聊天     10"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/nfp/data0117.csv', encoding='gbk')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14595326"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['times'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
